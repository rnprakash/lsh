\documentclass[a4paper]{article}
\usepackage[margin=1.5in]{geometry}
\usepackage{parskip,amsmath,mathtools,amssymb,amsfonts}
\usepackage{enumerate}
\usepackage{url,titling}
%\usepackage{ulem}
\usepackage{fancyhdr,hyperref}
\usepackage{booktabs,color,tabularx}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\innerproduct}[2]{\langle{}#1,#2\rangle{}}
\newtheorem{definition}{Definition}
\newtheorem{assumption}[definition]{Assumption}
\newtheorem{proposition}[definition]{Proposition}
\newtheorem{lemma}[definition]{Lemma}
\newtheorem{claim}[definition]{Claim}
\newtheorem{theorem}[definition]{Theorem}
\newtheorem{corollary}[definition]{Corollary}

\setlength{\textfloatsep}{6pt}


% Math symbols
\DeclareMathAlphabet{\mathcal}{OMS}{cmsy}{m}{n}
\newcommand{\A}[0]{\mathcal{A}}
\newcommand{\e}[1]{\text{e}^{#1}}
\newcommand{\E}[1]{\mathbf{E}\left[#1\right]}
\newcommand{\p}[0]{\mathbf{p}}
\newcommand{\q}[0]{\mathbf{q}}
\newcommand{\R}[0]{\mathbb{R}}
\newcommand{\re}[1]{\frac{1}{#1}}
\newcommand{\set}[1]{\lbrace\ 0,1 \rbrace^{#1}}
\newcommand{\X}[0]{\mathcal{X}}
\newcommand{\Y}[0]{\mathcal{Y}}
\newcommand{\Z}[0]{\mathbb{Z}}
\newcommand{\aand}[0]{\text{ and }}
\newcommand{\iif}[0]{\text{ if }}
\newcommand{\ow}[0]{\text{ otherwise}}

\newcommand{\todo}[1]{}
\renewcommand{\todo}[1]{{\color{red} TODO\@: {#1}}}

\setlength{\droptitle}{-8em}
\title{Ranked Leakage-Sensitive Hashing}
\author{Rohith Prakash}
\date{}

\begin{document}
\maketitle{}

\section{Introduction}
\label{sec:intro}

Time series are used almost ubiquitously to represent time-based measurements from any number of avenues.
However, it is a well known problem that when these times series represent behavior-related observations of complex systems, unintended information about the system may be leaked through this channel~\cite{DBLP:conf/ccs/RistenpartTSS09,DBLP:conf/sp/ZhangJOR11}.
This problem of side channel leakage has been extensively studied in the past by, and others have proposed correlation-based metrics to quantify the amount of leakage~\cite{demme2012,zhang2013}.

In this paper, we consider the problem of efficiently learning and classifying the behavior of side channels through observed time series using probabilistic hashing techniques.
We formally define the probability of information leakage on a set of such time series traces observed at a fixed granularity with respect to a distance metric.
By expanding on that intuition, we propose a \textit{ranked leakage-sensitive hashing} scheme based on previous locality-sensitive hashing schemes~\cite{Kulis12-KLSH,Jiang15-KLSH,Kim16-SLSH} that exploits the probability of information leakage for nearest neighbor computations in anomaly detection and behavior classification.
We believe that these contributions lead to a novel, strong characterization of leakage over side channels, giving rise to a new notion of \textit{dimensionality} of a channel.
We show that this can determine the effectiveness of leakage prevention schemes as well as discuss possibilities of projecting onto higher and lower dimensional spaces to improve anomaly detection or improve the effectiveness of leakage prevention schemes.

\section{Background and Definitions}
\label{sec:definitions}

% Definition of leakage
% Hashing
% LSH hash family
% Anomaly detection-specific:
% Distance metric
%
\subsection{Information Leakage}
\label{subsec:information_leakage}
Side channel exploitation, anomaly detection, and covert channel communication are problems of detecting or exploiting leakage over information channels.
Side and covert channels exists when observable differences in system behavior occur as the result of actions performed by a \textit{victim} or sending process.
These attacks typically involve an adversary learning secret information over the channel, based on the behavior of a victim process.
Anomaly detection, on the other hand, involves detectors running on a system analyzing and categorizing observed behavior in real time.
In this setting, a malicious program leaks information about its behavior through an observed channel.

%To formally define information leakage and the ability to exploit or thwart leakage, 
We consider a single information channel as a sequence of observations of a system resource --- a \textit{time series} of resource observations.
For example, the \textit{trace} of system calls on a system over time is an $n$-dimensional time series, where each observation determines the number of times each of the $n$ system calls was invoked.

Our primary observation with regards to time series leakage is that information may only be learned from time series observations if the underlying distributions are distinguishable.
If  

\begin{definition}\label{defn:dist_leakage}
    \textbf{Distribution-based leakage:} Consider two distinct program behaviors $x$ and $x'$ and resulting time series for each behavior drawn from $D_x$ and $D_{x'}$ respectively.
    Let $t(x)$ and $t(x')$ be two time series resulting from behaviors $x, x'$, drawn from $D_x, D_{x'}$ respectively.
    Observing $t(x)$ and $t(x')$ can only leak information about $x$ and $x'$ if $D_x$, $D_{x'}$ are statistically distinguishable.
\end{definition}

While Definition~\ref{defn:dist_leakage} is useful when one can carefully observe many samples from different distributions to assess the distinguishability of the underlying distributions, it is difficult to use in practice.
Instead, we propose a slightly different definition of leakage:

\begin{definition}\label{defn:leakage}
	\textbf{Time series leakage:} Consider two distinct program behaviors $x$ and $x'$ with output distributions $D_x$ and $D_{x'}$, and let $d(\cdot,\cdot)$ be a distance function on space of output time series.
    Let $T_x = \{t_k\}$ be a sequence of time series drawn from $D_x$.
    Define $r$ as the minimum distance such that $d(t_i, t_j) \le r~\forall~t_i,t_j \in T_x$

    We say that observing time series $t(x)$ and $t(x')$ can \textbf{leak information with respect to $d(\cdot,\cdot)$} about $x$ and $x'$ if $d(t(x),t(x')) > r$.
\end{definition}

Definition~\ref{defn:leakage} describes time series leakage with respect to a specific distance function applied on observation points.
If time series resulting from behavior $x$ can be separated from time series from $x'$ by a distance of more than $r$, there is potential information leakage through this channel.

\subsection{Hashing}
\label{subsec:hashing}
Hashing has long been used as a method of easing the curse of dimensionality for tasks such as clustering on a large set of high-dimensional data~\cite{Indyk98-ANN,Gionis99-SSH,Datar04-LSH}.
By exploiting the probabilistic nature and the computational efficiency of hashing, it is possible perform approximations to difficult high-dimensional problems quickly and in real-time.

Consider the space of time series $S$ and a distance metric $d$ on $S$.
A LSH family is defined as such:

\begin{definition}\label{def:hash_family}
    A hash family $\mathcal{H} = \{ h : S \rightarrow U \}$ is called $(r_1, r_2, p_1, p_2)$-sensitive w.r.t. $d(\cdot,\cdot)$ if for any $x,y \in S$
    \begin{enumerate}[(i)]
        \item\label{itm:hash_def1} If $d(x,y) \le r_1$, then $\Pr[h(x) = h(y)] \ge p_1$
        \item\label{itm:hash_def2} If $d(x,y) \ge r_2$, then $\Pr[h(x) = h(y)] \le p_2$
    \end{enumerate}
\end{definition}

Such a family is only interesting if $p_1 > p_2$.
To increase the effectiveness of an LSH technique, the gap between $p_1$ and $p_2$ may be \textit{amplified}:

\begin{definition}\label{def:lsh_amplification}
    Consider a $(r_1, r_2, p_1, p_2)$-sensitive hash family $\mathcal{H}$ w.r.t $d(\cdot,\cdot)$. The LSH hash family can be amplified in the following ways:
    \begin{enumerate}[(i)]
        \item \textbf{AND construction:} Define $\mathcal{H}' : S \rightarrow U^r$ such that for $h' \in \mathcal{H}'$, $h' = [h_1, \ldots, h_r] \subset \mathcal{H}$.
            $h'(x) = h'(y)$ iff $h_i(x) = h_i(y) ~\forall~h_i \in h'$
            $\mathcal{H'}$ is a $(r_1, r_2, p_1^r, p_2^r)$-sensitive LSH family
        \item \textbf{OR construction:} Define $\mathcal{H}' : S \rightarrow U^b$ such that for $h' \in \mathcal{H}'$, $h' = [h_1, \ldots, h_b] \subset \mathcal{H}$.
            $h'(x) = h'(y)$ iff $h_i(x) = h_i(y)$ for any $h_i \in h'$
            $\mathcal{H'}$ is a $(r_1, r_2, 1-{(1-p_1)}^b, 1-{(1-p_2)}^b)$-sensitive LSH family
        \item \textbf{AND-OR composition:} The composition of \textnormal{and} with \textnormal{or} constructions defines a $(r_1, r_2, 1-{(1-p_1^r)}^b, 1-{(1-p_2^r)}^b)$-sensitive LSH family
    \end{enumerate}
\end{definition}

We consider hash families $\mathcal{H} : S \rightarrow \mathbb{R}_{+}$ such that $h \in \mathcal{H}$ approximates $d(\cdot,\cdot)$ on time series.
Intuitively, time series which are ``closer'' to each other (as defined by some metric $d$) will be harder to distinguish by any arbitrary classifier and thus present fewer possibilities for information leakage.
We expand on this intuition by considering a hashing family $\mathcal{H}$ and hashing function $h \in \mathcal{H}$ which has the following property:

\begin{enumerate}[*]
    \item\label{itm:hash_def3}
        A set of families ${\{\mathcal{H}_r\}}_{r\in R}$ obeys the triangle inequality w.r.t. $d(\cdot,\cdot)$ such that it strictly obeys Definition~\ref{def:hash_family} for a set of distances $R$.
\end{enumerate}

\begin{definition}\label{defn:ranked_lsh}
    A set of hash families ${\{\mathcal{H}_r\}}_{r\in R}$ is a ranked LSH family if it is a $(r,r,p_1,p_2)$-sensitive hash family for every $r \in R$.
    Denote such a family as a $(R,p_1,p_2)$-sensitive LSH family $\mathcal{H}_R$.
\end{definition}

In summary, we are now considering a \textit{ranked LSH family} with the following properties:
\begin{proposition}\label{prop:ranked_lsh}
    There exists $(R,p_1,p_2)$-sensitive ranked LSH family $\mathcal{H}_R$ such that the following three hold:
    \begin{enumerate}[(i)]
        \item\label{itm:first} $h \in \mathcal{H}_r \in \mathcal{H}_R$ collides with high probability if $y \in B_r(x)$: $d(x,y) < r \Rightarrow \Pr[h(x) = h(y)] \ge p_1 p_2$.
        \item\label{itm:second} $h \in \mathcal{H}_r \in \mathcal{H}_R$ has few false collisions: If $d(x,y) > r$, $\Pr[h(x) = h(y)] < p_2$.
    \end{enumerate}
\end{proposition}

Properties (\ref{itm:first}) and (\ref{itm:second}) corroborate the notion of closeness to collision probabilities, which allows for the grouping of similar time series.
Due to Definition~\ref{defn:ranked_lsh}, we may apply iterative hashing scheme to \textit{rank} the probabilities of closeness based on the varied parameter $r$.
We discuss this in greater depth in Section~\ref{subsec:ranked_lsh}

\subsection{Distance Metric}
Denote the space of a time series as $S$, and define a metric $d$:

\begin{align*}
    d \colon S^2 &\to \mathbb{R}_{+}\\
    (x,y) &\mapsto r \numberthis
\end{align*}

Where $d$ maps two time series to a non-negative real number that represents some notion of distance between them.
Since $d$ is a metric, it obeys the triangle inequality~\cite{rosenlicht68-realanalysis}:

\begin{align*}
    d(x,y) \le d(x,z) + d(z,y) \numberthis
\end{align*}

% What do we need from this metric?

The function $d(\cdot,\cdot)$ helps define in our model what may be considered as information leakage.

% Why triangle inequality is important for ranking

% Discussion of time series comparison for leakage, in general

Simple Euclidean distance will not suffice, as it has many limitations for time series comparison~\cite{weighted-dtw}.
Dynamic Time Warping (DTW) presents a much more accurate method for comparing time series, but it does not satisfy the triangle inequality and is thus not a metric.
We could leverage an approximate lower-bound DTW~\cite{Lemire09-DTW} as this satisfies the triangle inequality, but recent literature~\cite{Kulis12-KLSH,Jiang15-KLSH,Kim16-SLSH} provide additional metrics which have proven efficiency and accuracy in fields such as image processing and classification.
Reproducing kernel Hilbert spaces have been studied with respect to locality sensitive hashing methods and may be of great use to this problem.

\subsection{Reproducing Kernel Hilbert Space}

\textit{Reproducing kernel Hilbert spaces (RKHS)} are a Hilbert spaces (vector spaces over which inner products are defined) defined over functions with the following property:
\begin{enumerate}[(i)]
    \item For any two functions $f,g \in H$ defined over $dom(f)$, $\norm{f-g}_{H} < \epsilon \Rightarrow |f(x)-g(x)| < \delta~\forall~x \in dom(f)$. 
\end{enumerate}

We consider time series to be discrete-time functions in an arbitrary RKHS and leverage kernelized LSH schemes~\cite{Kale14-KLSH,Jiang15-KLSH, Kulis12-KLSH} to perform our ranked hashing.
Since RKHS have a useful norm which intrinsically arises from their construction, we can leverage the norm in constructing a kernelized hash family to perform an explicit embedding.
Note, however, that this norm is not necessarily a Euclidean, point-wise norm.
The reverse, $|f(x)-g(x)| < \delta \Rightarrow \norm{f-g}_{H} < \epsilon$, need not be true in this space.

\section{Hashing model for privacy}

Consider a database of $n$ samples $D = \{x_1,\ldots,x_n\} \subset \mathbb{R}^d$ with feature map:

\begin{align*}
    \Phi \colon \mathbb{R}^d &\to \mathcal{H} \numberthis
\end{align*}

where $\mathcal{H}$ is a RKHS\@.
A kernelized hashing scheme for a similarity metric requires that each hash function $h_r$ satisfy:

\begin{align*}
    \Pr[h_r(x_i) = h_r(x_j)] = \kappa_r(x_i, x_j) \numberthis
    \label{eqn:hash_collision}
\end{align*}

where $\kappa(\cdot,\cdot)$ is a kernel function defined by:

\begin{align*}
    \kappa(x_i,x_j) = \innerproduct{\Phi(x_i)}{\Phi(x_j)} \numberthis
\end{align*}

We assume $\kappa_r$ is normalized with respect to distance bias $r$ such that $\kappa_r(\cdot,\cdot) \in [0,1]$, and $\kappa_r$ follows properties (\ref{itm:first}), (\ref{itm:second}), and (\ref{itm:third}) of Section~\ref{sec:intro}.

Note that equation~\ref{eqn:hash_collision} confers similar ``bounds'' to the differential privacy condition~\cite{dwork2006}:

\begin{align*}
    \Pr[f(x) = o] \le e^{\epsilon} \Pr[f(y) = o] \numberthis
    \label{eqn:differential_privacy}
\end{align*}

Intuitively, this bounds the probability ratio of an observed output $o$ being the result of inputs $x$ or $y$ to some function $f$.
While the hashing metric in equation~\ref{eqn:hash_collision} does not give a hard bound, it instead allows the evaluation of privacy leakage and the clear separation of time series into ranked buckets by varying distance parameter $r$.

\subsection{Ranked Hashing by Iteration}
\label{subsec:ranked_lsh}

Consider a hash family $\mathcal{H}$ which approximates a metric for time series distance and is parametrizable by distance threshold $r$ for collision probability (see properties (\ref{itm:first}), (\ref{itm:second}), and (\ref{itm:third}) in Section~\ref{sec:intro}).
%The key property of $h_r \in \mathcal{H}_r$ is that $\Pr[h_r(x) = h_r(y)]$ approximates $\kappa(x,y) < r$, where $\kappa(\cdot,\cdot)$ is the kernel function.

Let $\mathcal{R} = \{r_1, r_2, \ldots\}$ be a set of stratifying distance thresholds, and let $S$ be the space of all possible time series.
Define an equivalence relation $\sim_r$ on $S$ where $x \sim_r y \Leftrightarrow \kappa(x,y) < r$.
Then, $\pi_r$ is a projection mapping of $\sim_r$ such that $\pi_r \colon X \rightarrow X/\sim_r$, where $\pi_r(x) = \pi_r(y)$ iff $\kappa(x,y) < r$.

Iteratively applying LSH with hash functions $h_r \in \mathcal{H}_r~\forall r\in \mathcal{R}$ will approximate the projections $\pi_r$ for each threshold.
Let $L_r = \{[h_r(x)], \ldots \}$ be the set of LSH buckets (the set unique hash mappings of $h_r$).
If $h_r \approx \pi_r$, then $L_r$ will closely approximate the quotient $X/\sim_r$ and thus $\{L_r | r \in \mathcal{R} \} \approx \{X/\sim_r\}$.

\subsection{Anomaly Detection}
\label{subsec:anomaly_detection}

What this theory describes is that similar time series can be grouped together and ranked by their closeness by kernel function $\kappa$~\cite{Hachiya13-NSH}.
In the context of anomaly detection, we can apply this scheme to a set of \textit{normal} traces (time series of utilization, label encoded syscalls, etc.) to determine what thresholds and buckets constitute normal execution with a finer granularity.
Instead of a binary label of \textit{normal} vs \textit{anomalous}, we can instead stratify applications by types of execution.
We speculate that this makes our detection algorithm more robust to adversarial interference.

Given the initial LSH bucketing of normal traces, we can continuously apply the hashing scheme to testing traces over a rolling window to categorize their behavior.
Traces which do not match enough previously ``normal'' buckets over the set of thresholds may be considered to represent anomalous activity.


\subsection{Unsupervised, Intelligent Adversary}

A similar approach to Section~\ref{subsec:anomaly_detection} can be applied without a predetermined training set for time series classification through clustering.
Adjusting the set of threshold values confers the notion of closeness, which may be used to determine which sets of output traces resulted from the same input to a program, for example.

\section{Proposed Metrics}

Consider the Minkowski distance:

\begin{align*}
    M(x,y) = {(\sum\limits_k |x_k - y_k|^p)}^{1/p}
\end{align*}

For $p \ge 1$, $M(\cdot,\cdot)$ is a metric due to Minkowski's inequality~\cite[p. 190]{wheeden15-measure}.
Additionally, for $p = 2$, this is the standard Euclidean distance.
Like the Euclidean distance, this distance metric fails to account for phase and shape changes between time series.

To this end, we consider two different metrics based on a $p$-dimensional Minkowski distance.
The first is due to Batista et al.~\cite{batista14-cid} which attempts to account for time series complexity and has been shown to greatly improve the mean accuracy rates of time series comparison~\cite{giusti13-ecd}.
Consider the following \textit{complexity measure}:

\begin{align*}
    C(x) = \sqrt{\sum\limits_i {(q_i - q_{i+1})}^2} \numberthis
\end{align*}

Using this complexity measure, we define a \textit{complexity-invariant} distance metric based on the Minkowski distance $M(\cdot,\cdot)$:

\begin{align*}
    d(x,y) = M(x,y) * \frac{\max(C(x),C(y))}{\min(C(x),C(y))} \numberthis
\end{align*}

The second metric we consider attempts to correlate Minkowski distance across time with an additional penalty term for time series which are out of phase:

\begin{align*}
    d(x,y) = \min\limits_{i,j<\frac{n}{2}} \{ M(x[i:N],y[j:N]) + c*(i+j) \} \numberthis \\
\end{align*}

where $x,y$ have length $n$ and $N = n - \max(i,j)$.
$c$ is a scalar penalty factor for out of phase alignment between $x$ and $y$.

For both of these metrics, we consider $p$-dimensional Minkowski distance where the original time series have length $p$.

\subsection{Proposed Hash}

Let $S$ be the space of $n$-point time series to be processed.
Pick $a$ random lines in $\mathbb{R}^2$ and project each point $x_i$ onto each line $h_k$.
Each line will be partitioned into buckets of size $\frac{r}{n}$ (here, we see the parametrization of the hash).
In practice, we fix a number $M$ (say, $2^{32}$), and apply $h_r(x) = \frac{\pi(x)*n}{r} \bmod M$. 

Points are considered to intersect if they hash to the same bucket on a fixed number of hash function.
We propose that the number of hash functions on which points must collide to determine intersection be a tunable parameter.
Time series which intersect on more than $\frac{n}{2}$ points (in time order) are said to be candidate pairs for $r$-closeness.

\section{Key Takeaways}

\begin{itemize}
    \item Use hash that approximates time series distance.
    \item Compose multiple kernels or hash families to obtain ranked ``normality'' metric.
    \item Apply ranking to classification by an unsupervised classifier to determine amount of leakage possible without prior knowledge.
    \item Apply ranking to normality (anomaly) detection.
    \item Perform continuous hashing on rolling windows of execution across channels of multiple resources to classify activity in real-time.
    \item To be considered: Overlay results with ShapeGD\@.
\end{itemize}

\bibliographystyle{unsrt}
\bibliography{../bibliography/bibliography}

\end{document}
