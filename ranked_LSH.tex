\documentclass[a4paper]{article}
\usepackage[margin=1.5in]{geometry}
\usepackage{parskip,amsmath,mathtools,amssymb,amsfonts,mathrsfs}
\usepackage{enumerate}
\usepackage{url,titling}
%\usepackage{ulem}
\usepackage{fancyhdr,hyperref}
\usepackage{booktabs,color,tabularx}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\innerproduct}[2]{\langle{}#1,#2\rangle{}}
\newtheorem{definition}{Definition}
\newtheorem{assumption}[definition]{Assumption}
\newtheorem{proposition}[definition]{Proposition}
\newtheorem{lemma}[definition]{Lemma}
\newtheorem{claim}[definition]{Claim}
\newtheorem{theorem}[definition]{Theorem}
\newtheorem{corollary}[definition]{Corollary}

\setlength{\textfloatsep}{6pt}


% Math symbols
\DeclareMathAlphabet{\mathcal}{OMS}{cmsy}{m}{n}
\newcommand{\A}[0]{\mathcal{A}}
\newcommand{\e}[1]{\text{e}^{#1}}
\newcommand{\E}[1]{\mathbf{E}\left[#1\right]}
\newcommand{\p}[0]{\mathbf{p}}
\newcommand{\q}[0]{\mathbf{q}}
\newcommand{\R}[0]{\mathbb{R}}
\newcommand{\re}[1]{\frac{1}{#1}}
\newcommand{\set}[1]{\lbrace\ 0,1 \rbrace^{#1}}
\newcommand{\X}[0]{\mathcal{X}}
\newcommand{\Y}[0]{\mathcal{Y}}
\newcommand{\Z}[0]{\mathbb{Z}}
\newcommand{\aand}[0]{\text{ and }}
\newcommand{\iif}[0]{\text{ if }}
\newcommand{\ow}[0]{\text{ otherwise}}

\newcommand{\todo}[1]{}
\renewcommand{\todo}[1]{{\color{red} TODO\@: {#1}}}

\setlength{\droptitle}{-8em}
\title{Ranked Leakage-Sensitive Hashing}
\author{Rohith Prakash}
\date{}

\begin{document}
\maketitle{}

\begin{abstract}
    In this paper, we study the problem of real-time anomaly detection of intelligent malware samples disguised within benign applications. 
    We demonstrate that commonly used Dynamic Time Warping (DTW) distance is not suitable on time series of system resource traces when malware samples dynamically adapt their behavior to evade to evade detection.
    To deal with malware samples in real-time which attempt to hide within benign behavior, we propose a new LSH-based scheme that has low hardware and complexity overhead, iteratively hashes time series based on \textit{behavioral patterns}, triangulates hashing buckets to better categorize behavior, and is able to categorize new, previously unobserved behavior.
\end{abstract}

\section{Introduction}
\label{sec:intro}

Time series are used almost ubiquitously to represent time-based measurements from any number of avenues.
However, it is a well known problem that when these times series represent behavior-related observations of complex systems, unintended information about the system may be leaked through this channel~\cite{DBLP:conf/ccs/RistenpartTSS09,DBLP:conf/sp/ZhangJOR11}.
This problem of side channel leakage has been extensively studied in the past by, and others have proposed correlation-based measures to quantify the amount of leakage~\cite{demme2012,zhang2013}.

In this paper, we consider the problem of efficiently learning and classifying the behavior of side channels through observed time series using probabilistic hashing techniques.
We formally define the probability of information leakage on a set of such time series traces observed at a fixed granularity with respect to a distance measure.
By expanding on that intuition, we propose a \textit{ranked leakage-sensitive hashing} scheme based on previous locality-sensitive hashing schemes~\cite{Kulis12-KLSH,Jiang15-KLSH,Kim16-SLSH} that exploits the probability of information leakage for nearest neighbor computations in anomaly detection and behavior classification.
We believe that these contributions lead to a novel, strong characterization of leakage over side channels, giving rise to a new notion of \textit{dimensionality} of a channel.
We show that this can determine the effectiveness of leakage prevention schemes as well as discuss possibilities of projecting onto higher and lower dimensional spaces to improve anomaly detection or improve the effectiveness of leakage prevention schemes.

\section{Background and Definitions}
\label{sec:definitions}

% Definition of leakage
% Hashing
% LSH hash family
% Anomaly detection-specific:
% Distance metric

\subsection{Information Leakage}
\label{subsec:information_leakage}
Side channel exploitation, anomaly detection, and covert channel communication are problems of detecting or exploiting leakage over information channels.
Side and covert channels exists when observable differences in system behavior occur as the result of actions performed by a \textit{victim} or sending process.
These attacks typically involve an adversary learning secret information over the channel, based on the behavior of a victim process.
Anomaly detection, on the other hand, involves detectors running on a system analyzing and categorizing observed behavior in real time.
In this setting, a malicious program leaks information about its behavior through an observed channel.

%To formally define information leakage and the ability to exploit or thwart leakage, 
We consider a single information channel as a sequence of observations of a system resource --- a \textit{time series} of resource observations.
For example, the \textit{trace} of system calls on a system over time is an $n$-dimensional time series, where each observation determines the number of times each of the $n$ system calls was invoked.

Our primary observation with regards to time series leakage is that information may only be learned from time series observations if the underlying distributions are distinguishable.

\begin{definition}\label{defn:dist_leakage}
    \textbf{Distribution-based leakage:} Consider two distinct program behaviors $x$ and $x'$ and resulting time series for each behavior drawn from $D_x$ and $D_{x'}$ respectively.
    Let $t(x)$ and $t(x')$ be two time series resulting from behaviors $x, x'$, drawn from $D_x, D_{x'}$ respectively.
    Observing $t(x)$ and $t(x')$ can only leak information about $x$ and $x'$ if $D_x$, $D_{x'}$ are statistically distinguishable.
\end{definition}

While Definition~\ref{defn:dist_leakage} is useful when one can carefully observe many samples from different distributions to assess the distinguishability of the underlying distributions, it is difficult to use in practice.
Instead, we propose a slightly different definition of leakage:

\begin{definition}\label{defn:leakage}
	\textbf{Time series leakage:} Consider two distinct program behaviors $x$ and $x'$ with output distributions $D_x$ and $D_{x'}$, and let $d(\cdot,\cdot)$ be a distance function on space of output time series.
    Let $T_x = \{t_k\}$ be a sequence of time series drawn from $D_x$.
    Define $r$ as the minimum distance such that $d(t_i, t_j) \le r~\forall~t_i,t_j \in T_x$

    We say that observing time series $t(x)$ and $t(x')$ can \textbf{leak information with respect to $d(\cdot,\cdot)$} about $x$ and $x'$ if $d(t(x),t(x')) > r$.
\end{definition}

Definition~\ref{defn:leakage} describes time series leakage with respect to a specific distance function applied on observation points.
If time series resulting from behavior $x$ can be separated from time series from $x'$ by a distance of more than $r$, there is potential information leakage through this channel.

\subsection{Hashing}
\label{subsec:hashing}
Hashing has long been used as a method of easing the curse of dimensionality for tasks such as clustering on a large set of high-dimensional data~\cite{Indyk98-ANN,Gionis99-SSH,Datar04-LSH}.
Exploiting the probabilistic nature and the computational efficiency of hashing enables approximations to difficult high-dimensional problems quickly and in real-time.

Consider the space of time series $S$ and a distance function $d$ on $S$.
A LSH family is defined as such:

\begin{definition}\label{defn:hash_family}
    \textbf{Hash family:}
    A hash family $\mathcal{H} = \{ h : S \rightarrow U \}$ is called $(r_1, r_2, p_1, p_2)$-sensitive w.r.t. $d(\cdot,\cdot)$ if for any $x,y \in S, h \in \mathcal{H}$
    \begin{enumerate}[(i)]
        \item\label{itm:hash_def1} If $d(x,y) \le r_1$, then $\Pr[h(x) = h(y)] \ge p_1$
        \item\label{itm:hash_def2} If $d(x,y) \ge r_2$, then $\Pr[h(x) = h(y)] \le p_2$
    \end{enumerate}
\end{definition}

Such a family is only interesting if $p_1 > p_2$.
To increase the effectiveness of an LSH technique, the gap between $p_1$ and $p_2$ may be \textit{amplified}:

\begin{definition}\label{defn:lsh_amplification}
    \textbf{LSH Amplification:}
    Consider a $(r_1, r_2, p_1, p_2)$-sensitive hash family $\mathcal{H}$ w.r.t $d(\cdot,\cdot)$. The LSH hash family can be amplified in the following ways:
    \begin{enumerate}[(i)]
        \item \textbf{AND construction:} Define $\mathcal{H}' = \{h' : S \rightarrow U^r\}$ such that $h' = [h_1, \ldots, h_r] \subset \mathcal{H}$.
            $h'(x) = h'(y)$ iff $h_i(x) = h_i(y) ~\forall~h_i \in h'$
            $\mathcal{H'}$ is a $(r_1, r_2, p_1^r, p_2^r)$-sensitive LSH family
        \item \textbf{OR construction:} Define $\mathcal{H}' = \{h' : S \rightarrow U^b\}$ such that $h' = [h_1, \ldots, h_b] \subset \mathcal{H}$.
            $h'(x) = h'(y)$ iff $h_i(x) = h_i(y)$ for any $h_i \in h'$
            $\mathcal{H'}$ is a $(r_1, r_2, 1-{(1-p_1)}^b, 1-{(1-p_2)}^b)$-sensitive LSH family
        \item \textbf{AND-OR composition:} The composition of \textnormal{and} with \textnormal{or} constructions defines a $(r_1, r_2, 1-{(1-p_1^r)}^b, 1-{(1-p_2^r)}^b)$-sensitive LSH family
    \end{enumerate}
\end{definition}

We consider hash families $\mathcal{H} = \{h : S \rightarrow \mathbb{R}_{+}^n\}$ such that $h \in \mathcal{H}$ approximates $d(\cdot,\cdot)$ on time series in $S$.
Intuitively, time series which are ``closer'' to each other (as defined by $d$) will be harder to distinguish by any arbitrary classifier and thus present fewer possibilities for information leakage.
We expand on this intuition by considering a hashing family $\mathcal{H}$ and hashing function $h \in \mathcal{H}$ which has the following property $\mathscr{A}$:

% Can we make any claims about the reverse:
% Collision -> probability of collision with higher distance?
% This allows us to triangulate: you gain information about a "higher" hash family from a "lower" one

\begin{definition}\label{defn:property_alpha}
    \textbf{Property $\mathscr{A}$}:
    Two hash families $\mathcal{H}_{r_1}, \mathcal{H}_{r_2}$ ($r_1 \le r_2$ \textnormal{WLOG}) have property $\mathscr{A}$ if they are $(r_1, r_1, p_1, q_1)$ and $(r_2, r_2, p_2, q_2)$-sensitive respectively and the following holds:
    If $h_{r_1}(x) = h_{r_1}(y)$, then $\Pr[h_{r_2}(x) = h_{r_2}(y)] \le \max(1 - q_1, 1 - q_2)$
\end{definition}

Note that the function $d(\cdot,\cdot)$ used in constructing an LSH family need not be a proper metric, but property~$\mathscr{A}$ requires that $d(\cdot,\cdot)$ be sub-additive.

Definition~\ref{defn:property_alpha} allows for a stratified LSH scheme using a set of LSH families index by a distance $r$ which allows us to confer a notion of closeness between buckets of a lower LSH strata.

\begin{definition}\label{defn:ranked_lsh}
    \textbf{Ranked LSH families}:
    A set of hash families ${\{\mathcal{H}_r\}}_{r\in R}$ is a ranked LSH family if any two $H_{r_1}, H_{r_2}$ have property $\mathscr{A}~\forall~r_1, r_2 \in R$.
    Denote such a set of families as $(R,p_1, p_2)$-sensitive LSH families $\mathcal{H}_R$.
    %, where $p = \inf\{ p_i | H_{r_1}$ is $(r_1,r_1,p_i,p_i)$-sensitive $\}$.
\end{definition}

%In summary, we are now considering a \textit{ranked LSH family} with the following properties:
\begin{proposition}\label{prop:ranked_lsh}
    There exists $(R, p_1, p_2)$-sensitive ranked LSH families $\mathcal{H}_R = {\{\mathcal{H}_r\}}_{r\in R}$ such that the following hold:
    \begin{enumerate}[(i)]
        \item\label{itm:first}
            $h \in \mathcal{H}_r \in \mathcal{H}_R$ collides with high probability if $y \in B_r(x)$: If $d(x,y) < r, \Pr[h(x) = h(y)] \ge p_1$.
        \item\label{itm:second}
            $h \in \mathcal{H}_r$ has few false collisions: If $d(x,y) > r$, $\Pr[h(x) = h(y)] < p_2$.
        \item\label{itm:rank_property}
            Property $\mathscr{A}$ holds for any two families $\mathcal{H}_{r_1}, \mathcal{H}_{r_2} \in \mathcal{H}_R$.
    \end{enumerate}
\end{proposition}

Proposition~\ref{prop:ranked_lsh} corroborates the notion of closeness to collision probabilities, which allows for the grouping of similar time series.
Due to Property~$\mathscr{A}$, we may apply iterative hashing scheme to \textit{rank} the probabilities of closeness based on the varied parameter $r$.
We discuss this in greater depth in Section~\ref{subsec:ranked_lsh}

\subsection{Distance Measure}
Denote the space of a time series as $S$, and define a function $d$:

\begin{align*}
    d \colon S^2 &\to \mathbb{R}_{+}\\
    (x,y) &\mapsto r \numberthis
\end{align*}

Where $d$ maps two time series to a non-negative real number that represents some notion of distance between them.
Additionally, require $d$ to be sub-additive:

\begin{align*}
    d(x,y) \le d(x,z) + d(z,y) \numberthis
\end{align*}

% What do we need from this metric?

The function $d(\cdot,\cdot)$ defines leakage in our threat model.
To give intuition behind this, we consider an arbitrary classification attack on a set of time series.
Applying Definitions~\ref{defn:dist_leakage} and~\ref{defn:leakage}, there is potential for leakage by observing the resulting time series if, for some function $d$, there exists separation by $d(\cdot, \cdot)$ between time series of differing classes.

% Why triangle inequality is important for ranking

% Suppose d(x,y) > r1 but h(x) = h(y)
% Then: let z = proj(y) onto B(r,x)
% d(x,z) = r1
% Then d(x,y) \le d(x,z) + d(z,y)
% Then wat

% Discussion of time series comparison for leakage, in general

Previous work in time series anomaly detection has largely focused on Euclidean distance and Dynamic Time Warping (DTW) distance.
However, we note that there are drawbacks of limiting evaluation to these two measures only.
DTW is not a proper metric as it is not sub-additive; this is a result of DTW treating one time series as non-linear time-stretched of the other.
In the context of anomaly detection, this limits the ability to mark a small, unexpected change in behavior when compared with other distance measures.
Additionally, both of these measures operate under the assumption that observed time series which are similar will be of the same scale.
Two time series which exhibit similar ``behavior'' but take values of a slightly different scale will not be marked as being similar by either measure.
Changes in background system activity could therefore affect the ability of these two measure to detect true anomalous activity.

\subsection{Kernel Transforms}
\label{subsec:kernel_transforms}

We have so far defined leakage with respect to an arbitrary, but fixed, distance measure.
However, we now consider kernel transforms to define higher dimensional distance measures without explicitly defining the embedding space.
This methodology allows us to determine a leakage-sensitive distance measure with computational efficiency.

Kernel transforms have been used extensively in machine learning problems, especially in support vector machine (SVM) classifiers. 
For example, a kernel transform allows the use of user-specified similarity functions that may be computationally intractable to fully define.
However, kernel transforms have also been recently applied to hashing problems in order to tackle even higher dimensional similarity problems~\cite{Kulis12-KLSH, Kale14-KLSH, Jiang15-KLSH}.
A kernel function $\kappa(\cdot,\cdot)$ thus defines a new similarity measure on a higher dimensional space over which we would not otherwise be able to efficiently hash.
%Generalizing the hashing methodology to accept any similarity measure by using arbitrary kernel transforms allows for efficient 

The following definitions let us formally define kernel transforms on time series:
h
\begin{definition}\label{defn:hilbert_space}
    \textbf{Hilbert space}:
    A vector space $X$ over a field $F$ with an inner product $\innerproduct{\cdot}{\cdot}: X \times X \rightarrow F$ that also defines a complete\footnote{A space $X$ is complete if every Cauchy sequence ($\{x_n\}_{n \in \mathbb{N}}, x_n \in X$) converges in $X$.} metric space is called a Hilbert space.
\end{definition}

\begin{definition}\label{defn:kernel_trick}
    \textbf{Kernel transform}:
    Let $X$ be an arbitrary space and $H$ be a Hilbert space with inner product $\innerproduct{\cdot}{\cdot}_H$.
    $\kappa(\cdot, \cdot): X \times X \rightarrow H$ is a kernel transform if $\kappa(x,y) = \innerproduct{\phi(x)}{\phi(y)}_H$ for some $\phi: X \rightarrow H$.
\end{definition}

Note that in Definition~\ref{defn:kernel_trick}, the mapping function $\phi$ need not be explicitly defined.
In fact, $\kappa$ being a positive-semidefinite function (or matrix over discrete spaces) implies the existence of a satisfactory function $\phi$.
Thus, we can consider arbitrary higher-order distance measures as any positive-semidefinite mapping $\kappa: X \times X \rightarrow H$ guarantees a similarity measure in $H$.

\begin{definition}\label{defn:rkhs}
    \textbf{Reproducing kernel Hilbert space (RKHS)}:
    Let $H$ be a Hilbert space of real-valued functions on an arbitrary set $X$.
    $H$ is a reproducing kernel Hilbert space if there exists a \textbf{reproducing kernel} for all $x \in X$, $\kappa_x$, where $f(x) = \innerproduct{f}{\kappa_x}_H~\forall~f \in H$.
\end{definition}

Note that $\kappa(x,y) = \innerproduct{\kappa_x}{\kappa_y}_H$, and thus the kernel transform in Definition~\ref{defn:kernel_trick} defines a RKHS.
We have thus demonstrated that we can consider arbitrary higher-order similarity measures using kernel functions on the space of observed samples.

\section{Hashing model}
\label{sec:hashing}

Consider a set of $n$ samples $D = \{x_1,\ldots,x_n\} \subset \mathbb{R}^d$ with feature map:

\begin{align*}
    \Phi \colon \mathbb{R}^d &\to \mathcal{H} \numberthis
\end{align*}

where $\mathcal{H}$ is a RKHS\@.
A kernelized hashing scheme for a similarity measure requires that each hash function $h_r$ satisfy:

\begin{align*}
    \Pr[h_r(x_i) = h_r(x_j)] = \kappa_r(x_i, x_j) \numberthis
    \label{eqn:hash_collision}
\end{align*}

where $\kappa(\cdot,\cdot)$ is a kernel function defined by:

\begin{align*}
    \kappa(x_i,x_j) = \innerproduct{\Phi(x_i)}{\Phi(x_j)} \numberthis
\end{align*}

We assume $\kappa_r$ is normalized with respect to distance bias $r$ such that $\kappa_r(\cdot,\cdot) \in [0,1]$, and $\kappa_r$ follows properties (\ref{itm:first}), (\ref{itm:second}), and (\ref{itm:third}) of Section~\ref{sec:intro}.

Note that equation~\ref{eqn:hash_collision} confers similar ``bounds'' to the differential privacy condition~\cite{dwork2006}:

\begin{align*}
    \Pr[f(x) = o] \le e^{\epsilon} \Pr[f(y) = o] \numberthis
    \label{eqn:differential_privacy}
\end{align*}

Intuitively, this bounds the probability ratio of an observed output $o$ being the result of inputs $x$ or $y$ to some function $f$.
While the hashing measure in equation~\ref{eqn:hash_collision} does not give a hard bound, it instead allows the evaluation of privacy leakage and the clear separation of time series into ranked buckets by varying distance parameter $r$.

\subsection{Ranked Hashing by Iteration}
\label{subsec:ranked_lsh}

Consider a hash family $\mathcal{H}$ which approximates a measure for time series distance and is parametrizable by distance threshold $r$ for collision probability (see properties (\ref{itm:first}), (\ref{itm:second}), and (\ref{itm:third}) in Section~\ref{sec:intro}).
%The key property of $h_r \in \mathcal{H}_r$ is that $\Pr[h_r(x) = h_r(y)]$ approximates $\kappa(x,y) < r$, where $\kappa(\cdot,\cdot)$ is the kernel function.

Let $\mathcal{R} = \{r_1, r_2, \ldots\}$ be a set of stratifying distance thresholds, and let $S$ be the space of all possible time series.
Define an equivalence relation $\sim_r$ on $S$ where $x \sim_r y \Leftrightarrow \kappa(x,y) < r$.
Then, $\pi_r$ is a projection mapping of $\sim_r$ such that $\pi_r \colon X \rightarrow X/\sim_r$, where $\pi_r(x) = \pi_r(y)$ iff $\kappa(x,y) < r$.

Iteratively applying LSH with hash functions $h_r \in \mathcal{H}_r~\forall r\in \mathcal{R}$ will approximate the projections $\pi_r$ for each threshold.
Let $L_r = \{[h_r(x)], \ldots \}$ be the set of LSH buckets (the set unique hash mappings of $h_r$).
If $h_r \approx \pi_r$, then $L_r$ will closely approximate the quotient $X/\sim_r$ and thus $\{L_r | r \in \mathcal{R} \} \approx \{X/\sim_r\}$.

\subsection{Anomaly Detection}
\label{subsec:anomaly_detection}

What this theory describes is that similar time series can be grouped together and ranked by their closeness by kernel function $\kappa$~\cite{Hachiya13-NSH}.
In the context of anomaly detection, we can apply this scheme to a set of \textit{normal} traces (time series of utilization, label encoded syscalls, etc.) to determine what thresholds and buckets constitute normal execution with a finer granularity.
Instead of a binary label of \textit{normal} vs \textit{anomalous}, we can instead stratify applications by types of execution.
We speculate that this makes our detection algorithm more robust to adversarial interference.

Given the initial LSH bucketing of normal traces, we can continuously apply the hashing scheme to testing traces over a rolling window to categorize their behavior.
Traces which do not match enough previously ``normal'' buckets over the set of thresholds may be considered to represent anomalous activity.


\subsection{Unsupervised, Intelligent Adversary}

A similar approach to Section~\ref{subsec:anomaly_detection} can be applied without a predetermined training set for time series classification through clustering.
Adjusting the set of threshold values confers the notion of closeness, which may be used to determine which sets of output traces resulted from the same input to a program, for example.

\section{Proposed Measures}

Consider the Minkowski distance:

\begin{align*}
    M(x,y) = {(\sum\limits_k |x_k - y_k|^p)}^{1/p}
\end{align*}

For $p \ge 1$, $M(\cdot,\cdot)$ is a measure due to Minkowski's inequality~\cite[p. 190]{wheeden15-measure}.
Additionally, for $p = 2$, this is the standard Euclidean distance.
Like the Euclidean distance, this distance metric fails to account for phase and shape changes between time series.

To this end, we consider two different measures based on a $p$-dimensional Minkowski distance.
The first is due to Batista et al.~\cite{batista14-cid} which attempts to account for time series complexity and has been shown to greatly improve the mean accuracy rates of time series comparison~\cite{giusti13-ecd}.
Consider the following \textit{complexity measure}:

\begin{align*}
    C(x) = \sqrt{\sum\limits_i {(q_i - q_{i+1})}^2} \numberthis
\end{align*}

Using this complexity measure, we define a \textit{complexity-invariant} distance measure based on the Minkowski distance $M(\cdot,\cdot)$:

\begin{align*}
    d(x,y) = M(x,y) * \frac{\max(C(x),C(y))}{\min(C(x),C(y))} \numberthis
\end{align*}

The second measure we consider attempts to correlate Minkowski distance across time with an additional penalty term for time series which are out of phase:

\begin{align*}
    d(x,y) = \min\limits_{i,j<\frac{n}{2}} \{ M(x[i:N],y[j:N]) + c*(i+j) \} \numberthis \\
\end{align*}

where $x,y$ have length $n$ and $N = n - \max(i,j)$.
$c$ is a scalar penalty factor for out of phase alignment between $x$ and $y$.

For both of these measures, we consider $p$-dimensional Minkowski distance where the original time series have length $p$.

\subsection{Proposed Hash}

Let $S$ be the space of $n$-point time series to be processed.
Pick $a$ random lines in $\mathbb{R}^2$ and project each point $x_i$ onto each line $h_k$.
Each line will be partitioned into buckets of size $\frac{r}{n}$ (here, we see the parametrization of the hash).
In practice, we fix a number $M$ (say, $2^{32}$), and apply $h_r(x) = \frac{\pi(x)*n}{r} \bmod M$. 

Points are considered to intersect if they hash to the same bucket on a fixed number of hash function.
We propose that the number of hash functions on which points must collide to determine intersection be a tunable parameter.
Time series which intersect on more than $\frac{n}{2}$ points (in time order) are said to be candidate pairs for $r$-closeness.

\section{Key Takeaways}

\begin{itemize}
    \item Use hash that approximates time series distance.
    \item Compose multiple kernels or hash families to obtain ranked ``normality'' measure.
    \item Apply ranking to classification by an unsupervised classifier to determine amount of leakage possible without prior knowledge.
    \item Apply ranking to normality (anomaly) detection.
    \item Perform continuous hashing on rolling windows of execution across channels of multiple resources to classify activity in real-time.
    \item To be considered: Overlay results with ShapeGD\@.
\end{itemize}

\bibliographystyle{unsrt}
\bibliography{../bibliography/bibliography}

\end{document}
